{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "\n",
    "# Data Engineering Capstone Project - Immigration Data Analytical Database\n",
    "\n",
    "#### Project Summary\n",
    "My capstone project automates the data cleaning and loading process using Airflow and Redshift. Data files are located in s3 bucket. Main database consists of one fact table and multiple dimension tables. Additional datasets are loaded into staging tables. \n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "import awswrangler as wr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "For my data engineering capstone project I developed a data pipeline that creates an analytical database and supporting tables. Analytical database contain US immigration data populated on a monthly basis. Additional datasets are also available in staging tables. Insights can be drawn from main analytical tables or combining with other information tables provided. All data files are hosted in Amazon s3 bucket.  Tables are hosted in Amazon Redshift Database and ETL/ELT pipeline was developed using Apache Airflow.\n",
    "\n",
    "\n",
    "### Datasets\n",
    "Following datasets were used to create analytical database:\n",
    "- I94 Immigration Data: This dataset comes from the US National Tourism and Trade Office. Each data file contains monthly information on international visitors arrival. Data fields include information on arrival departure time frame, citizenship country, residence country, arrival mode, and some traveller information such as birth year, age at arrival, occupation, gender etc. Each file contains 28 data columns and 3 million rows. Immigration data comes with a data dictionary that defines column contents of the main dataset which can be parsed and used in building the data model.\n",
    "\n",
    "\n",
    "*I94 immigration data sample:*\n",
    "\n",
    "![I94 immigration data sample1](./images/immig1.png)\n",
    "![I94 immigration data sample2](./images/immig2.png)\n",
    "\n",
    "\n",
    "- World Temperature Data: This kaggle dataset contains city, country, latitude, longitude, average temperature, and temperature uncertainty data.\n",
    "\n",
    " *World temperature data sample:*\n",
    "\n",
    "![world-temperature](./images/world-temp.png)\n",
    "\n",
    "- U.S. City Demographic Data: This dataset contains information about the demographics of all US cities and census-designated places with a population greater than or equal to 65,0000. Dataset comes from OpenSoft.\n",
    "\n",
    "*U.S. city demographic data sample:*\n",
    "\n",
    "![city-demo](./images/city-demo.png)\n",
    "\n",
    "- Airport Codes: This dataset contains data on airport codes and corresponding cities. According to wikipedia, The airport codes may refer to either IATA airport code, a three-letter code which is used in passenger reservation, ticketing and baggage-handling systems, or the ICAO airport code which is a four letter code used by ATC systems and for airports that do not have an IATA airport code. \n",
    "\n",
    "*Airport Codes data sample:*\n",
    "\n",
    "![Airport-codes](./images/airport.png)\n",
    "\n",
    "- Manually Collected Data: Additional datasets describing gender definitions, and visa classes were collected through online research. These datasets improves the capabilities of main analytical database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read in the data here. Change path based on your data file location.\n",
    "pd.set_option('display.max_columns', None)\n",
    "fname = './data/immigration/18-83510-I94-Data-2016/i94_jan16_sub.sas7bdat'\n",
    "pd.set_option('display.max_columns', None)\n",
    "df = pd.read_sas(fname, 'sas7bdat', encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>count</th>\n",
       "      <th>dtadfile</th>\n",
       "      <th>visapost</th>\n",
       "      <th>occup</th>\n",
       "      <th>entdepa</th>\n",
       "      <th>entdepd</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>BOS</td>\n",
       "      <td>20465.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>D/S</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LH</td>\n",
       "      <td>346608285.0</td>\n",
       "      <td>424</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>BOS</td>\n",
       "      <td>20465.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>D/S</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LH</td>\n",
       "      <td>346627585.0</td>\n",
       "      <td>424</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>BOS</td>\n",
       "      <td>20469.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CT</td>\n",
       "      <td>20480.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>07152016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AF</td>\n",
       "      <td>381092385.0</td>\n",
       "      <td>338</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>BOS</td>\n",
       "      <td>20469.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CT</td>\n",
       "      <td>20499.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>07152016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AF</td>\n",
       "      <td>381087885.0</td>\n",
       "      <td>338</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>BOS</td>\n",
       "      <td>20469.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CT</td>\n",
       "      <td>20499.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>07152016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AF</td>\n",
       "      <td>381078685.0</td>\n",
       "      <td>338</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode i94addr  \\\n",
       "0    7.0  2016.0     1.0   101.0   101.0     BOS  20465.0      1.0      MA   \n",
       "1    8.0  2016.0     1.0   101.0   101.0     BOS  20465.0      1.0      MA   \n",
       "2    9.0  2016.0     1.0   101.0   101.0     BOS  20469.0      1.0      CT   \n",
       "3   10.0  2016.0     1.0   101.0   101.0     BOS  20469.0      1.0      CT   \n",
       "4   11.0  2016.0     1.0   101.0   101.0     BOS  20469.0      1.0      CT   \n",
       "\n",
       "   depdate  i94bir  i94visa  count dtadfile visapost occup entdepa entdepd  \\\n",
       "0      NaN    20.0      3.0    1.0      NaN      NaN   NaN       T     NaN   \n",
       "1      NaN    20.0      3.0    1.0      NaN      NaN   NaN       T     NaN   \n",
       "2  20480.0    17.0      2.0    1.0      NaN      NaN   NaN       T       N   \n",
       "3  20499.0    45.0      2.0    1.0      NaN      NaN   NaN       T       N   \n",
       "4  20499.0    12.0      2.0    1.0      NaN      NaN   NaN       T       N   \n",
       "\n",
       "  entdepu matflag  biryear   dtaddto gender insnum airline       admnum fltno  \\\n",
       "0     NaN     NaN   1996.0       D/S      M    NaN      LH  346608285.0   424   \n",
       "1     NaN     NaN   1996.0       D/S      M    NaN      LH  346627585.0   424   \n",
       "2     NaN       M   1999.0  07152016      F    NaN      AF  381092385.0   338   \n",
       "3     NaN       M   1971.0  07152016      F    NaN      AF  381087885.0   338   \n",
       "4     NaN       M   2004.0  07152016      M    NaN      AF  381078685.0   338   \n",
       "\n",
       "  visatype  \n",
       "0       F1  \n",
       "1       F1  \n",
       "2       B2  \n",
       "3       B2  \n",
       "4       B2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2847924 entries, 0 to 2847923\n",
      "Data columns (total 28 columns):\n",
      " #   Column    Dtype  \n",
      "---  ------    -----  \n",
      " 0   cicid     float64\n",
      " 1   i94yr     float64\n",
      " 2   i94mon    float64\n",
      " 3   i94cit    float64\n",
      " 4   i94res    float64\n",
      " 5   i94port   object \n",
      " 6   arrdate   float64\n",
      " 7   i94mode   float64\n",
      " 8   i94addr   object \n",
      " 9   depdate   float64\n",
      " 10  i94bir    float64\n",
      " 11  i94visa   float64\n",
      " 12  count     float64\n",
      " 13  dtadfile  object \n",
      " 14  visapost  object \n",
      " 15  occup     object \n",
      " 16  entdepa   object \n",
      " 17  entdepd   object \n",
      " 18  entdepu   object \n",
      " 19  matflag   object \n",
      " 20  biryear   float64\n",
      " 21  dtaddto   object \n",
      " 22  gender    object \n",
      " 23  insnum    object \n",
      " 24  airline   object \n",
      " 25  admnum    float64\n",
      " 26  fltno     object \n",
      " 27  visatype  object \n",
      "dtypes: float64(13), object(15)\n",
      "memory usage: 608.4+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cicid             0\n",
       "i94yr             0\n",
       "i94mon            0\n",
       "i94cit            0\n",
       "i94res            0\n",
       "i94port           0\n",
       "arrdate           0\n",
       "i94mode          60\n",
       "i94addr      177129\n",
       "depdate      522612\n",
       "i94bir         1190\n",
       "i94visa           0\n",
       "count             0\n",
       "dtadfile      90486\n",
       "visapost    1386375\n",
       "occup       2802355\n",
       "entdepa          61\n",
       "entdepd      521813\n",
       "entdepu     2847880\n",
       "matflag      521813\n",
       "biryear        1190\n",
       "dtaddto         707\n",
       "gender       216929\n",
       "insnum      2709236\n",
       "airline       61279\n",
       "admnum            0\n",
       "fltno         12232\n",
       "visatype          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for columns with null values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this code to copy sas file to s3 bucket in parquet format.\n",
    "#wr.s3.to_parquet(df, \"s3://hg-dend/sas-files/i94_jan16_sub.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>count</th>\n",
       "      <th>dtadfile</th>\n",
       "      <th>visapost</th>\n",
       "      <th>occup</th>\n",
       "      <th>entdepa</th>\n",
       "      <th>entdepd</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2700037</th>\n",
       "      <td>6036966.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>SAI</td>\n",
       "      <td>20465.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20468.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160316</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>L</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1942.0</td>\n",
       "      <td>02252016</td>\n",
       "      <td>F</td>\n",
       "      <td>3975</td>\n",
       "      <td>OZ</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>00627</td>\n",
       "      <td>GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2697887</th>\n",
       "      <td>6034811.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>AGA</td>\n",
       "      <td>20478.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160316</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>03092016</td>\n",
       "      <td>F</td>\n",
       "      <td>3660</td>\n",
       "      <td>TW</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>00311</td>\n",
       "      <td>GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2637012</th>\n",
       "      <td>5953924.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>SAI</td>\n",
       "      <td>20456.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20460.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160301</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>L</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1973.0</td>\n",
       "      <td>02162016</td>\n",
       "      <td>F</td>\n",
       "      <td>3988</td>\n",
       "      <td>OZ</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>00607</td>\n",
       "      <td>GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2637011</th>\n",
       "      <td>5953923.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>SAI</td>\n",
       "      <td>20456.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20458.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160301</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>L</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>02162016</td>\n",
       "      <td>M</td>\n",
       "      <td>3993</td>\n",
       "      <td>7C</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>03404</td>\n",
       "      <td>GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2698071</th>\n",
       "      <td>6034995.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>AGA</td>\n",
       "      <td>20478.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160316</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>03092016</td>\n",
       "      <td>M</td>\n",
       "      <td>3688</td>\n",
       "      <td>TW</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>00311</td>\n",
       "      <td>GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2143587</th>\n",
       "      <td>4818518.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>20454.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>AZ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160126</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>03302016</td>\n",
       "      <td>M</td>\n",
       "      <td>3297</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.427546e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2806692</th>\n",
       "      <td>5949292.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>LUK</td>\n",
       "      <td>20472.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>AZ</td>\n",
       "      <td>20479.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160301</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Z</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1965.0</td>\n",
       "      <td>04172016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.427546e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>WB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2632638</th>\n",
       "      <td>5949308.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>20462.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>AZ</td>\n",
       "      <td>20479.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160301</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1965.0</td>\n",
       "      <td>04172016</td>\n",
       "      <td>M</td>\n",
       "      <td>3303</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.427546e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49980</th>\n",
       "      <td>71726.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>20473.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>03282016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G6B</td>\n",
       "      <td>9.463559e+10</td>\n",
       "      <td>94130</td>\n",
       "      <td>CP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2622107</th>\n",
       "      <td>5930595.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>MOB</td>\n",
       "      <td>20473.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160210</td>\n",
       "      <td>MAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>07192016</td>\n",
       "      <td>M</td>\n",
       "      <td>2460</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.463559e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32360 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode  \\\n",
       "2700037  6036966.0  2016.0     1.0   254.0   276.0     SAI  20465.0      1.0   \n",
       "2697887  6034811.0  2016.0     1.0   254.0   276.0     AGA  20478.0      1.0   \n",
       "2637012  5953924.0  2016.0     1.0   254.0   276.0     SAI  20456.0      1.0   \n",
       "2637011  5953923.0  2016.0     1.0   254.0   276.0     SAI  20456.0      1.0   \n",
       "2698071  6034995.0  2016.0     1.0   254.0   276.0     AGA  20478.0      1.0   \n",
       "...            ...     ...     ...     ...     ...     ...      ...      ...   \n",
       "2143587  4818518.0  2016.0     1.0   111.0   111.0     XXX  20454.0      9.0   \n",
       "2806692  5949292.0  2016.0     1.0   129.0   129.0     LUK  20472.0      3.0   \n",
       "2632638  5949308.0  2016.0     1.0   129.0   582.0     XXX  20462.0      9.0   \n",
       "49980      71726.0  2016.0     1.0   260.0   260.0     XXX  20473.0      9.0   \n",
       "2622107  5930595.0  2016.0     1.0   260.0   260.0     MOB  20473.0      9.0   \n",
       "\n",
       "        i94addr  depdate  i94bir  i94visa  count  dtadfile visapost occup  \\\n",
       "2700037     NaN  20468.0    74.0      2.0    1.0  20160316      NaN   NaN   \n",
       "2697887      GU      NaN    56.0      2.0    1.0  20160316      NaN   NaN   \n",
       "2637012     NaN  20460.0    43.0      2.0    1.0  20160301      NaN   NaN   \n",
       "2637011     NaN  20458.0    35.0      2.0    1.0  20160301      NaN   NaN   \n",
       "2698071      GU      NaN     4.0      2.0    1.0  20160316      NaN   NaN   \n",
       "...         ...      ...     ...      ...    ...       ...      ...   ...   \n",
       "2143587      AZ      NaN    33.0      2.0    1.0  20160126      NaN   NaN   \n",
       "2806692      AZ  20479.0    51.0      1.0    1.0  20160301      NaN   NaN   \n",
       "2632638      AZ  20479.0    51.0      1.0    1.0  20160301      NaN   NaN   \n",
       "49980        AL      NaN    39.0      2.0    1.0       NaN      NaN   NaN   \n",
       "2622107      TX      NaN    39.0      2.0    1.0  20160210      MAN   NaN   \n",
       "\n",
       "        entdepa entdepd entdepu matflag  biryear   dtaddto gender insnum  \\\n",
       "2700037       A       L     NaN       M   1942.0  02252016      F   3975   \n",
       "2697887       A     NaN     NaN     NaN   1960.0  03092016      F   3660   \n",
       "2637012       A       L     NaN       M   1973.0  02162016      F   3988   \n",
       "2637011       A       L     NaN       M   1981.0  02162016      M   3993   \n",
       "2698071       A     NaN     NaN     NaN   2012.0  03092016      M   3688   \n",
       "...         ...     ...     ...     ...      ...       ...    ...    ...   \n",
       "2143587       A     NaN     NaN     NaN   1983.0  03302016      M   3297   \n",
       "2806692       Z       D     NaN       M   1965.0  04172016      M    NaN   \n",
       "2632638       A       D     NaN       M   1965.0  04172016      M   3303   \n",
       "49980         U     NaN     NaN     NaN   1977.0  03282016      M    NaN   \n",
       "2622107       P     NaN     NaN     NaN   1977.0  07192016      M   2460   \n",
       "\n",
       "        airline        admnum  fltno visatype  \n",
       "2700037      OZ  0.000000e+00  00627      GMT  \n",
       "2697887      TW  0.000000e+00  00311      GMT  \n",
       "2637012      OZ  0.000000e+00  00607      GMT  \n",
       "2637011      7C  0.000000e+00  03404      GMT  \n",
       "2698071      TW  0.000000e+00  00311      GMT  \n",
       "...         ...           ...    ...      ...  \n",
       "2143587     NaN  9.427546e+10    NaN       WT  \n",
       "2806692     NaN  9.427546e+10   LAND       WB  \n",
       "2632638     NaN  9.427546e+10    NaN       WB  \n",
       "49980       G6B  9.463559e+10  94130       CP  \n",
       "2622107     NaN  9.463559e+10    NaN       CP  \n",
       "\n",
       "[32360 rows x 28 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if addnum is unique and can be used as primary key\n",
    "mask = df.admnum.duplicated(keep=False)\n",
    "df[mask].sort_values(by=['admnum'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Airport data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 55075 entries, 0 to 55074\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   ident         55075 non-null  object \n",
      " 1   type          55075 non-null  object \n",
      " 2   name          55075 non-null  object \n",
      " 3   elevation_ft  48069 non-null  float64\n",
      " 4   continent     27356 non-null  object \n",
      " 5   iso_country   54828 non-null  object \n",
      " 6   iso_region    55075 non-null  object \n",
      " 7   municipality  49399 non-null  object \n",
      " 8   gps_code      41030 non-null  object \n",
      " 9   iata_code     9189 non-null   object \n",
      " 10  local_code    28686 non-null  object \n",
      " 11  coordinates   55075 non-null  object \n",
      "dtypes: float64(1), object(11)\n",
      "memory usage: 5.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "airport_data = pd.read_csv(r'./data/airport/airport-codes_csv.csv', sep=',', encoding='UTF-8')\n",
    "print(airport_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if ident can be primary key\n",
    "len(airport_data)- len(airport_data.ident.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>237.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>Newport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-91.254898, 35.6087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                                name  elevation_ft  \\\n",
       "0   00A       heliport                   Total Rf Heliport          11.0   \n",
       "1  00AA  small_airport                Aero B Ranch Airport        3435.0   \n",
       "2  00AK  small_airport                        Lowell Field         450.0   \n",
       "3  00AL  small_airport                        Epps Airpark         820.0   \n",
       "4  00AR         closed  Newport Hospital & Clinic Heliport         237.0   \n",
       "\n",
       "  continent iso_country iso_region  municipality gps_code iata_code  \\\n",
       "0       NaN          US      US-PA      Bensalem      00A       NaN   \n",
       "1       NaN          US      US-KS         Leoti     00AA       NaN   \n",
       "2       NaN          US      US-AK  Anchor Point     00AK       NaN   \n",
       "3       NaN          US      US-AL       Harvest     00AL       NaN   \n",
       "4       NaN          US      US-AR       Newport      NaN       NaN   \n",
       "\n",
       "  local_code                            coordinates  \n",
       "0        00A     -74.93360137939453, 40.07080078125  \n",
       "1       00AA                 -101.473911, 38.704022  \n",
       "2       00AK            -151.695999146, 59.94919968  \n",
       "3       00AL  -86.77030181884766, 34.86479949951172  \n",
       "4        NaN                    -91.254898, 35.6087  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ident               0\n",
       "type                0\n",
       "name                0\n",
       "elevation_ft     7006\n",
       "continent       27719\n",
       "iso_country       247\n",
       "iso_region          0\n",
       "municipality     5676\n",
       "gps_code        14045\n",
       "iata_code       45886\n",
       "local_code      26389\n",
       "coordinates         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for null values\n",
    "airport_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coordinates are not in numeric format. Need to convert to numeric and clean null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test clean up. Final clean up will be done using sql\n",
    "values = {'elevation_ft': -99999, 'continent':'-','iso_country':'-', 'iso_country':'-', 'municipality':'-', 'gps_code':'-', 'iata_code':'-', 'local_code':'-'}\n",
    "airport_data.fillna(value=values, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### us-cities-demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "us_cities = pd.read_csv(r'./data/us-city-demo/us-cities-demographics.csv', sep=';', encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2891 entries, 0 to 2890\n",
      "Data columns (total 12 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   City                    2891 non-null   object \n",
      " 1   State                   2891 non-null   object \n",
      " 2   Median Age              2891 non-null   float64\n",
      " 3   Male Population         2888 non-null   float64\n",
      " 4   Female Population       2888 non-null   float64\n",
      " 5   Total Population        2891 non-null   int64  \n",
      " 6   Number of Veterans      2878 non-null   float64\n",
      " 7   Foreign-born            2878 non-null   float64\n",
      " 8   Average Household Size  2875 non-null   float64\n",
      " 9   State Code              2891 non-null   object \n",
      " 10  Race                    2891 non-null   object \n",
      " 11  Count                   2891 non-null   int64  \n",
      "dtypes: float64(6), int64(2), object(4)\n",
      "memory usage: 271.2+ KB\n"
     ]
    }
   ],
   "source": [
    "us_cities.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City                       0\n",
       "State                      0\n",
       "Median Age                 0\n",
       "Male Population            3\n",
       "Female Population          3\n",
       "Total Population           0\n",
       "Number of Veterans        13\n",
       "Foreign-born              13\n",
       "Average Household Size    16\n",
       "State Code                 0\n",
       "Race                       0\n",
       "Count                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_cities.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040.0</td>\n",
       "      <td>46799.0</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819.0</td>\n",
       "      <td>8229.0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127.0</td>\n",
       "      <td>87105.0</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821.0</td>\n",
       "      <td>33878.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040.0</td>\n",
       "      <td>143873.0</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829.0</td>\n",
       "      <td>86253.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State  Median Age  Male Population  \\\n",
       "0     Silver Spring       Maryland        33.8          40601.0   \n",
       "1            Quincy  Massachusetts        41.0          44129.0   \n",
       "2            Hoover        Alabama        38.5          38040.0   \n",
       "3  Rancho Cucamonga     California        34.5          88127.0   \n",
       "4            Newark     New Jersey        34.6         138040.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "2            46799.0             84839              4819.0        8229.0   \n",
       "3            87105.0            175232              5821.0       33878.0   \n",
       "4           143873.0            281913              5829.0       86253.0   \n",
       "\n",
       "   Average Household Size State Code                       Race  Count  \n",
       "0                    2.60         MD         Hispanic or Latino  25924  \n",
       "1                    2.39         MA                      White  58723  \n",
       "2                    2.58         AL                      Asian   4759  \n",
       "3                    3.18         CA  Black or African-American  24437  \n",
       "4                    2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_cities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Clean column names\n",
    "us_cities.columns = ['city', 'state_name', 'median_age', 'male_population', 'female_population',\n",
    "       'total_population', 'num_veterans', 'foreign_born',\n",
    "       'average_household_size', 'state_code', 'race', 'count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_cities['city'] = us_cities['city'].str.upper()\n",
    "us_cities['state_name'] = us_cities['city'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "567"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(us_cities.city.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state_name</th>\n",
       "      <th>median_age</th>\n",
       "      <th>male_population</th>\n",
       "      <th>female_population</th>\n",
       "      <th>total_population</th>\n",
       "      <th>num_veterans</th>\n",
       "      <th>foreign_born</th>\n",
       "      <th>average_household_size</th>\n",
       "      <th>state_code</th>\n",
       "      <th>race</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SILVER SPRING</td>\n",
       "      <td>SILVER SPRING</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QUINCY</td>\n",
       "      <td>QUINCY</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOOVER</td>\n",
       "      <td>HOOVER</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040.0</td>\n",
       "      <td>46799.0</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819.0</td>\n",
       "      <td>8229.0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RANCHO CUCAMONGA</td>\n",
       "      <td>RANCHO CUCAMONGA</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127.0</td>\n",
       "      <td>87105.0</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821.0</td>\n",
       "      <td>33878.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NEWARK</td>\n",
       "      <td>NEWARK</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040.0</td>\n",
       "      <td>143873.0</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829.0</td>\n",
       "      <td>86253.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               city        state_name  median_age  male_population  \\\n",
       "0     SILVER SPRING     SILVER SPRING        33.8          40601.0   \n",
       "1            QUINCY            QUINCY        41.0          44129.0   \n",
       "2            HOOVER            HOOVER        38.5          38040.0   \n",
       "3  RANCHO CUCAMONGA  RANCHO CUCAMONGA        34.5          88127.0   \n",
       "4            NEWARK            NEWARK        34.6         138040.0   \n",
       "\n",
       "   female_population  total_population  num_veterans  foreign_born  \\\n",
       "0            41862.0             82463        1562.0       30908.0   \n",
       "1            49500.0             93629        4147.0       32935.0   \n",
       "2            46799.0             84839        4819.0        8229.0   \n",
       "3            87105.0            175232        5821.0       33878.0   \n",
       "4           143873.0            281913        5829.0       86253.0   \n",
       "\n",
       "   average_household_size state_code                       race  count  \n",
       "0                    2.60         MD         Hispanic or Latino  25924  \n",
       "1                    2.39         MA                      White  58723  \n",
       "2                    2.58         AL                      Asian   4759  \n",
       "3                    3.18         CA  Black or African-American  24437  \n",
       "4                    2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_cities.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Load temperature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "fname = './data/world-temp/GlobalLandTemperaturesByCity.csv'\n",
    "temperature_data = pd.read_csv(fname, index_col=0, parse_dates=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1743-11-01</th>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743-12-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1744-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1744-02-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1744-03-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            AverageTemperature  AverageTemperatureUncertainty   City  Country  \\\n",
       "dt                                                                              \n",
       "1743-11-01               6.068                          1.737  Ã…rhus  Denmark   \n",
       "1743-12-01                 NaN                            NaN  Ã…rhus  Denmark   \n",
       "1744-01-01                 NaN                            NaN  Ã…rhus  Denmark   \n",
       "1744-02-01                 NaN                            NaN  Ã…rhus  Denmark   \n",
       "1744-03-01                 NaN                            NaN  Ã…rhus  Denmark   \n",
       "\n",
       "           Latitude Longitude  \n",
       "dt                             \n",
       "1743-11-01   57.05N    10.33E  \n",
       "1743-12-01   57.05N    10.33E  \n",
       "1744-01-01   57.05N    10.33E  \n",
       "1744-02-01   57.05N    10.33E  \n",
       "1744-03-01   57.05N    10.33E  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 8599212 entries, 1743-11-01 to 2013-09-01\n",
      "Data columns (total 6 columns):\n",
      " #   Column                         Dtype  \n",
      "---  ------                         -----  \n",
      " 0   AverageTemperature             float64\n",
      " 1   AverageTemperatureUncertainty  float64\n",
      " 2   City                           object \n",
      " 3   Country                        object \n",
      " 4   Latitude                       object \n",
      " 5   Longitude                      object \n",
      "dtypes: float64(2), object(4)\n",
      "memory usage: 459.2+ MB\n"
     ]
    }
   ],
   "source": [
    "temperature_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AverageTemperature               364130\n",
       "AverageTemperatureUncertainty    364130\n",
       "City                                  0\n",
       "Country                               0\n",
       "Latitude                              0\n",
       "Longitude                             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# null will be replaced with -999, longitude, latitude in NSEW format. will be coverted to numeric to be compatible with airport data\n",
    "temperature_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Clean up\n",
    "# short_temp_data.columns = ['avg_temp', 'avg_temp_error', 'city', 'country', 'latitude', 'longitude']\n",
    "# short_temp_data['city']  = short_temp_data.city.str.upper()\n",
    "# short_temp_data['country']  = short_temp_data.country.str.upper()\n",
    "# us_temp_data = short_temp_data[short_temp_data['country']=='UNITED STATES'].copy()\n",
    "# us_temp_data['latitude'] = us_temp_data['latitude'].apply(lambda x: (1 if x[-1] == 'N' else -1) * float(x[:-1]))\n",
    "# us_temp_data['longitude'] = us_temp_data['longitude'].apply(lambda x: (1 if x[-1]=='E' else -1)*float(x[:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read SAS data dictionary, parse to extract dimension tables.\n",
    "with open(r'./data/immigration/I94_SAS_Labels_Descriptions.SAS') as file:\n",
    "    file_string = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sas_source_code_tables_data = [\n",
    "  {'table_name': 'country',\n",
    "   'parse_string': 'i94cntyl',\n",
    "   'end_string': ';',\n",
    "   'columns': ['country_code', 'country'],\n",
    "   'dq_checks': [{'check_sql': \"SELECT COUNT(*) FROM country WHERE country_code is null\", 'expected_result': 0}]\n",
    "  },\n",
    "  {'table_name': 'entry_port',\n",
    "   'parse_string': 'i94prtl',\n",
    "   'end_string': ';',\n",
    "   'columns': ['port_code', 'addr', 'city', 'state'],\n",
    "   'dq_checks': [{'check_sql': \"SELECT COUNT(*) FROM entry_port WHERE port_code is null\", 'expected_result': 0}]\n",
    "  },\n",
    "  {'table_name': 'arrival_mode',\n",
    "   'parse_string': 'i94model',\n",
    "   'end_string': ';',\n",
    "   'columns': ['arrival_code', 'arrival_type'],\n",
    "   'dq_checks': [{'check_sql': \"SELECT COUNT(*) FROM arrival_mode WHERE arrival_code is null\", 'expected_result': 0}]\n",
    "  },\n",
    "  {'table_name': 'region',\n",
    "   'parse_string': 'i94addrl',\n",
    "   'end_string': ';',\n",
    "   'columns': ['region_code', 'region_name'],\n",
    "   'dq_checks': [{'check_sql': \"SELECT COUNT(*) FROM region_code WHERE region_code is null\", 'expected_result': 0}]\n",
    "  },\n",
    "  {'table_name': 'visa_type',\n",
    "   'parse_string': 'I94VISA',\n",
    "   'end_string': '*/',\n",
    "   'columns': ['visa_code', 'visa_type'],\n",
    "   'dq_checks': [{'check_sql': \"SELECT COUNT(*) FROM visa_type WHERE visa_code is null\", 'expected_result': 0}]\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_sas_file(file_string, parse_string, end_string, table_name, columns):\n",
    "    '''Function accepts sas file as a string, segments data tables base on parse_string and end_string.\n",
    "        It will further process string segment to clean and extract code and value fields as lists.\n",
    "        Function returns the ziped list of code and value.\n",
    "    \n",
    "    '''\n",
    "    filtered_string = file_string[file_string.index(parse_string):]\n",
    "    filtered_string = filtered_string[:filtered_string.index(end_string)]\n",
    "    # clean string  by removing ' and tabs\n",
    "    filtered_string = filtered_string.replace(\"'\", \"\").replace('\\t', \"\")\n",
    "    # Remove line with parse_string\n",
    "    filtered_list = filtered_string.split('\\n')\n",
    "    filtered_list = filtered_list[1:] \n",
    "\n",
    "    df = pd.DataFrame(filtered_list)\n",
    "    \n",
    "    df[[0,1]] = df[0].str.split('=', n = 1, expand = True)\n",
    "    df[0] = df[0].str.strip()\n",
    "    df[1] = df[1].str.strip()\n",
    "    df[0] = df[0].str.upper()\n",
    "    df[1] = df[1].str.upper()\n",
    "    df = df.dropna()\n",
    "   \n",
    "    if table_name=='entry_port':\n",
    "       \n",
    "        df[2] = df[1].apply(lambda x: x.split(',')[0].upper())\n",
    "        df[3] = df[1].apply(lambda x: x.split(',')[-1].upper())\n",
    "        df[2] = df[2].str.strip()\n",
    "        df[3] = df[3].str.strip()#ARPT\n",
    "        df[2] = df[2].str.replace(' #ARPT', \"\", regex = False)\n",
    "        df[3] = df[3].str.replace(' (BPS)', \"\", regex = False)\n",
    "        df[3] = df[3].str.replace(' #ARPT', \"\", regex = False)\n",
    "    \n",
    "        df.columns=columns\n",
    "    \n",
    "    else:\n",
    " \n",
    "        df.columns=columns\n",
    "\n",
    "    return df.drop_duplicates().dropna()\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test \n",
    "us_ports = parse_sas_file(file_string, 'i94prtl', ';', 'entry_port', ['port_code', 'addr', 'city', 'state']) \n",
    "#us_ports = parse_sas_file(file_string, 'I94VISA', '*/', 'visa_type', ['code', 'value'])\n",
    "#us_ports = parse_sas_file(file_string, 'i94model', ';', 'arrival_mode', ['code', 'value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>port_code</th>\n",
       "      <th>addr</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALC</td>\n",
       "      <td>ALCAN, AK</td>\n",
       "      <td>ALCAN</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANC</td>\n",
       "      <td>ANCHORAGE, AK</td>\n",
       "      <td>ANCHORAGE</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BAR</td>\n",
       "      <td>BAKER AAF - BAKER ISLAND, AK</td>\n",
       "      <td>BAKER AAF - BAKER ISLAND</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DAC</td>\n",
       "      <td>DALTONS CACHE, AK</td>\n",
       "      <td>DALTONS CACHE</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PIZ</td>\n",
       "      <td>DEW STATION PT LAY DEW, AK</td>\n",
       "      <td>DEW STATION PT LAY DEW</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  port_code                          addr                      city state\n",
       "0       ALC                     ALCAN, AK                     ALCAN    AK\n",
       "1       ANC                 ANCHORAGE, AK                 ANCHORAGE    AK\n",
       "2       BAR  BAKER AAF - BAKER ISLAND, AK  BAKER AAF - BAKER ISLAND    AK\n",
       "3       DAC             DALTONS CACHE, AK             DALTONS CACHE    AK\n",
       "4       PIZ    DEW STATION PT LAY DEW, AK    DEW STATION PT LAY DEW    AK"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_ports[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country\n",
      "entry_port\n",
      "arrival_mode\n",
      "region\n",
      "visa_type\n"
     ]
    }
   ],
   "source": [
    "# file strig is defind above\n",
    "for item in sas_source_code_tables_data:\n",
    "    parse_string = item.get('parse_string')\n",
    "    end_string = item.get('end_string')\n",
    "    table_name = item.get('table_name')\n",
    "    columns = item.get('columns')\n",
    "\n",
    "  \n",
    "    print(table_name)\n",
    " \n",
    "\n",
    "\n",
    "    dm_df = parse_sas_file(file_string, parse_string, end_string, table_name , columns)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read temperature data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Datasets have multiple quality issues such as null values, mixed numeric and string data, date formatting issues etc. Data cleanup is performed in Airflow using table specific sql queries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "U.S. Immigration analytical database has a star schema with one fact table and multiple dimension tables. Dimension tables are directly populated through truncate, copy pattern or special operator that parses and loads the data. Dimension tables are relatively small in size. Consequently, truncate-copy pattern is a reasonable way to to maintain idempotent data pipeline without compromising the performance. Dimension tables are distributed across all nodes for faster query performance. Immigration dataset is first loaded into staging a staging table, which will then be cleaned and populates that fact table.\n",
    "\n",
    "Additional datasets containing world temperature, US city demographics, and airport codes can be combined with main database to answer various analytical questions. These datasets are loaded into staging tables, cleaned and transformed into more analytical friendly formats.\n",
    "\n",
    "Database schema is shown below:\n",
    "\n",
    "![Main-dataset](./images/er_capstone.png)\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "Following custom operators were developed for loading datasets from s3 bucket to RedShift, cleaning, and validation. \n",
    "\n",
    "- SASfileToRedshiftOperator : Parse and load tables from SAS data dictionary to Redshift.\n",
    "- S3ToRedshiftOperator : Load files in CSV or Parquet format to Redshift using copy command.\n",
    "- LoadFactOperator : Clean and load immigration fact table from staging table.\n",
    "- CleanTablesOperator : Perform various data cleanup operations, for example fill null values, convert from string to numeric format etc.\n",
    "- DataQualityOperator : Performs data quality checks to ensure tables are populated without errors using pre-defined set of queries and expected result.\n",
    "\n",
    "Airflow data pipeline is shown below:\n",
    "\n",
    "![pipeline](./images/graph_success.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Implemented using Airflow. See [README.md](./README.md) for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Table specific quality checks are defined in Airflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file.\n",
    "\n",
    "Data dictionary file is available in csv format. [immigration_data_dict.csv](./immigration_data_dict.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "   1.  Apache Airflow is a great open source tool for easy scheduling of etl workflows. In this project Airflow is used to keep the analytical database up to date and to ensure data quality.\n",
    "\n",
    "   1. Redshift offers Massively parallel processing (MPP) that enables fast execution of the most complex queries operating on large amounts of data. Columnar storage of tables reduces i/o requirements and improves analytical query performance. Redshift is easily scalable and can be configured within minutes.\n",
    "\n",
    "   1. S3 object storage was selected as the raw data storage solution due to performance and redshift compatibility advantages.\n",
    "\n",
    "* Propose how often the data should be updated and why.\n",
    "    1. Immigration raw datasets are updated on monthly basis. Consequently, pipeline is scheduled monthly. It can be adjusted if data is available more frequently.\n",
    "\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    "    1. Airflow and Redshift are easily scalable to handle increased data load.\n",
    "\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    "    1. In this case DAG need to be scheduled on daily basis to ensure most updated datasets are available for the dash board update. \n",
    "\n",
    " * The database needed to be accessed by 100+ people.\n",
    "    1. AWS offers many options for identity and access management based on their roles. Redshift cluster resources may need scaling up based on demand. Redshift offer auto scaling based on demand, which maximizes performance while optimizing cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
