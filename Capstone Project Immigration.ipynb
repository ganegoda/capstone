{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "My capstone project automates the data cleaning and loading process using Airflow and Redshift. Data files are located in s3 bucket. Main database consists of one fact table and multiple dimension tables. Additional datasets are loaded into staging tables. \n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "import awswrangler as wr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "For my data engineering capstone project I developed a data pipeline that creates an analytical database and supporting tables. Analytical database contain US immigration data populated on a monthly basis. Additional datasets are also available in staging tables. Insights can be drawn from main analytical tables or combining with other information tables provided. All data files are hosted in Amazon s3 bucket.  Tables are hosted in Amazon Redshift Database and ETL/ELT pipeline was developed using Apache Airflow.\n",
    "\n",
    "\n",
    "### Datasets\n",
    "Following datasets were used to create analytical database:\n",
    "- I94 Immigration Data: This dataset comes from the US National Tourism and Trade Office. Each data file contains monthly information on international visitors arrival. Data fields include information on arrival departure time frame, citizenship country, residence country, arrival mode, and some traveller information such as birth year, age at arrival, occupation, gender etc. Each file contains 28 data columns and 3 million rows. Immigration data comes with a data dictionary that defines column contents of the main dataset which can be parsed and used in building the data model.\n",
    "\n",
    "\n",
    "*I94 immigration data sample:*\n",
    "\n",
    "![I94 immigration data sample1](./images/immig1.png)\n",
    "![I94 immigration data sample2](./images/immig2.png)\n",
    "\n",
    "\n",
    "- World Temperature Data: This kaggle dataset contains city, country, latitude, longitude, average temperature, and temperature uncertainty data.\n",
    "\n",
    " *World temperature data sample:*\n",
    "\n",
    "![world-temperature](./images/world-temp.png)\n",
    "\n",
    "- U.S. City Demographic Data: This dataset contains information about the demographics of all US cities and census-designated places with a population greater than or equal to 65,0000. Dataset comes from OpenSoft.\n",
    "\n",
    "*U.S. city demographic data sample:*\n",
    "\n",
    "![city-demo](./images/city-demo.png)\n",
    "\n",
    "- Airport Codes: This dataset contains data on airport codes and corresponding cities. According to wikipedia, The airport codes may refer to either IATA airport code, a three-letter code which is used in passenger reservation, ticketing and baggage-handling systems, or the ICAO airport code which is a four letter code used by ATC systems and for airports that do not have an IATA airport code. \n",
    "\n",
    "*Airport Codes data sample:*\n",
    "\n",
    "![Airport-codes](./images/airport.png)\n",
    "\n",
    "- Manually Collected Data: Additional datasets describing gender definitions, and visa classes were collected through online research. These datasets improves the capabilities of main analytical database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read in the data here. Change path based on your data file location.\n",
    "pd.set_option('display.max_columns', None)\n",
    "fname = './data/immigration/18-83510-I94-Data-2016/i94_jan16_sub.sas7bdat'\n",
    "pd.set_option('display.max_columns', None)\n",
    "df = pd.read_sas(fname, 'sas7bdat', encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>count</th>\n",
       "      <th>dtadfile</th>\n",
       "      <th>visapost</th>\n",
       "      <th>occup</th>\n",
       "      <th>entdepa</th>\n",
       "      <th>entdepd</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T</td>\n",
       "      <td>NaN</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>10282016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.897628e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20130811</td>\n",
       "      <td>SEO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>D/S</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.736796e+09</td>\n",
       "      <td>00296</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MI</td>\n",
       "      <td>20691.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160401</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OS</td>\n",
       "      <td>6.666432e+08</td>\n",
       "      <td>93</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160401</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160401</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode i94addr  \\\n",
       "0    6.0  2016.0     4.0   692.0   692.0     XXX  20573.0      NaN     NaN   \n",
       "1    7.0  2016.0     4.0   254.0   276.0     ATL  20551.0      1.0      AL   \n",
       "2   15.0  2016.0     4.0   101.0   101.0     WAS  20545.0      1.0      MI   \n",
       "3   16.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "4   17.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "\n",
       "   depdate  i94bir  i94visa  count  dtadfile visapost occup entdepa entdepd  \\\n",
       "0      NaN    37.0      2.0    1.0       NaN      NaN   NaN       T     NaN   \n",
       "1      NaN    25.0      3.0    1.0  20130811      SEO   NaN       G     NaN   \n",
       "2  20691.0    55.0      2.0    1.0  20160401      NaN   NaN       T       O   \n",
       "3  20567.0    28.0      2.0    1.0  20160401      NaN   NaN       O       O   \n",
       "4  20567.0     4.0      2.0    1.0  20160401      NaN   NaN       O       O   \n",
       "\n",
       "  entdepu matflag  biryear   dtaddto gender insnum airline        admnum  \\\n",
       "0       U     NaN   1979.0  10282016    NaN    NaN     NaN  1.897628e+09   \n",
       "1       Y     NaN   1991.0       D/S      M    NaN     NaN  3.736796e+09   \n",
       "2     NaN       M   1961.0  09302016      M    NaN      OS  6.666432e+08   \n",
       "3     NaN       M   1988.0  09302016    NaN    NaN      AA  9.246846e+10   \n",
       "4     NaN       M   2012.0  09302016    NaN    NaN      AA  9.246846e+10   \n",
       "\n",
       "   fltno visatype  \n",
       "0    NaN       B2  \n",
       "1  00296       F1  \n",
       "2     93       B2  \n",
       "3  00199       B2  \n",
       "4  00199       B2  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2847924 entries, 0 to 2847923\n",
      "Data columns (total 28 columns):\n",
      " #   Column    Dtype  \n",
      "---  ------    -----  \n",
      " 0   cicid     float64\n",
      " 1   i94yr     float64\n",
      " 2   i94mon    float64\n",
      " 3   i94cit    float64\n",
      " 4   i94res    float64\n",
      " 5   i94port   object \n",
      " 6   arrdate   float64\n",
      " 7   i94mode   float64\n",
      " 8   i94addr   object \n",
      " 9   depdate   float64\n",
      " 10  i94bir    float64\n",
      " 11  i94visa   float64\n",
      " 12  count     float64\n",
      " 13  dtadfile  object \n",
      " 14  visapost  object \n",
      " 15  occup     object \n",
      " 16  entdepa   object \n",
      " 17  entdepd   object \n",
      " 18  entdepu   object \n",
      " 19  matflag   object \n",
      " 20  biryear   float64\n",
      " 21  dtaddto   object \n",
      " 22  gender    object \n",
      " 23  insnum    object \n",
      " 24  airline   object \n",
      " 25  admnum    float64\n",
      " 26  fltno     object \n",
      " 27  visatype  object \n",
      "dtypes: float64(13), object(15)\n",
      "memory usage: 608.4+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cicid             0\n",
       "i94yr             0\n",
       "i94mon            0\n",
       "i94cit            0\n",
       "i94res            0\n",
       "i94port           0\n",
       "arrdate           0\n",
       "i94mode          60\n",
       "i94addr      177129\n",
       "depdate      522612\n",
       "i94bir         1190\n",
       "i94visa           0\n",
       "count             0\n",
       "dtadfile      90486\n",
       "visapost    1386375\n",
       "occup       2802355\n",
       "entdepa          61\n",
       "entdepd      521813\n",
       "entdepu     2847880\n",
       "matflag      521813\n",
       "biryear        1190\n",
       "dtaddto         707\n",
       "gender       216929\n",
       "insnum      2709236\n",
       "airline       61279\n",
       "admnum            0\n",
       "fltno         12232\n",
       "visatype          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for columns with null values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paths': ['s3://hg-dend/sas-files/i94_jan16_sub.parquet'],\n",
       " 'partitions_values': {}}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use this code to copy sas file to s3 bucket in parquet format.\n",
    "#wr.s3.to_parquet(df, \"s3://hg-dend/sas-files/i94_jan16_sub.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>count</th>\n",
       "      <th>dtadfile</th>\n",
       "      <th>visapost</th>\n",
       "      <th>occup</th>\n",
       "      <th>entdepa</th>\n",
       "      <th>entdepd</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2966361</th>\n",
       "      <td>5991259.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>SAI</td>\n",
       "      <td>20570.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160617</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>05072016</td>\n",
       "      <td>M</td>\n",
       "      <td>3890</td>\n",
       "      <td>7C</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>03404</td>\n",
       "      <td>CP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2960934</th>\n",
       "      <td>5983634.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>SAI</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20554.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160615</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>L</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>05212016</td>\n",
       "      <td>F</td>\n",
       "      <td>3980</td>\n",
       "      <td>OZ</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>00607</td>\n",
       "      <td>GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2960935</th>\n",
       "      <td>5983635.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>SAI</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20554.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160615</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>L</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>05212016</td>\n",
       "      <td>F</td>\n",
       "      <td>3969</td>\n",
       "      <td>OZ</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>00607</td>\n",
       "      <td>GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2961618</th>\n",
       "      <td>5984318.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>SAI</td>\n",
       "      <td>20553.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20556.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160615</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>L</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>05232016</td>\n",
       "      <td>F</td>\n",
       "      <td>3987</td>\n",
       "      <td>7C</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>03402</td>\n",
       "      <td>GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2962550</th>\n",
       "      <td>5985272.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>SAI</td>\n",
       "      <td>20554.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20558.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160615</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>L</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1974.0</td>\n",
       "      <td>05242016</td>\n",
       "      <td>U</td>\n",
       "      <td>3980</td>\n",
       "      <td>OZ</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3095512</th>\n",
       "      <td>5897900.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>696.0</td>\n",
       "      <td>696.0</td>\n",
       "      <td>BOA</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>20602.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160430</td>\n",
       "      <td>CDJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Z</td>\n",
       "      <td>I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>10282016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.492138e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2872019</th>\n",
       "      <td>5763033.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>352.0</td>\n",
       "      <td>352.0</td>\n",
       "      <td>SEA</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>20594.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160430</td>\n",
       "      <td>KMP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>U</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>05302016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EK</td>\n",
       "      <td>9.495698e+10</td>\n",
       "      <td>227</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2872018</th>\n",
       "      <td>5763032.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>352.0</td>\n",
       "      <td>352.0</td>\n",
       "      <td>SEA</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160430</td>\n",
       "      <td>KMP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>05302016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EK</td>\n",
       "      <td>9.495698e+10</td>\n",
       "      <td>00227</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2902934</th>\n",
       "      <td>5894436.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>691.0</td>\n",
       "      <td>691.0</td>\n",
       "      <td>YHC</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160430</td>\n",
       "      <td>BGT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>U</td>\n",
       "      <td>I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VES</td>\n",
       "      <td>9.499540e+10</td>\n",
       "      <td>AMSTR</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2902931</th>\n",
       "      <td>5894433.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>691.0</td>\n",
       "      <td>691.0</td>\n",
       "      <td>YHC</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160430</td>\n",
       "      <td>BGT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VES</td>\n",
       "      <td>9.499540e+10</td>\n",
       "      <td>AMSTR</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40108 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode  \\\n",
       "2966361  5991259.0  2016.0     4.0   245.0   245.0     SAI  20570.0      1.0   \n",
       "2960934  5983634.0  2016.0     4.0   254.0   276.0     SAI  20551.0      1.0   \n",
       "2960935  5983635.0  2016.0     4.0   254.0   276.0     SAI  20551.0      1.0   \n",
       "2961618  5984318.0  2016.0     4.0   254.0   276.0     SAI  20553.0      1.0   \n",
       "2962550  5985272.0  2016.0     4.0   254.0   276.0     SAI  20554.0      1.0   \n",
       "...            ...     ...     ...     ...     ...     ...      ...      ...   \n",
       "3095512  5897900.0  2016.0     4.0   696.0   696.0     BOA  20574.0      3.0   \n",
       "2872019  5763033.0  2016.0     4.0   352.0   352.0     SEA  20574.0      1.0   \n",
       "2872018  5763032.0  2016.0     4.0   352.0   352.0     SEA  20574.0      1.0   \n",
       "2902934  5894436.0  2016.0     4.0   691.0   691.0     YHC  20574.0      2.0   \n",
       "2902931  5894433.0  2016.0     4.0   691.0   691.0     YHC  20574.0      2.0   \n",
       "\n",
       "        i94addr  depdate  i94bir  i94visa  count  dtadfile visapost occup  \\\n",
       "2966361     NaN      NaN    31.0      2.0    1.0  20160617      NaN   NaN   \n",
       "2960934     NaN  20554.0    35.0      2.0    1.0  20160615      NaN   NaN   \n",
       "2960935     NaN  20554.0    10.0      2.0    1.0  20160615      NaN   NaN   \n",
       "2961618     NaN  20556.0    33.0      2.0    1.0  20160615      NaN   NaN   \n",
       "2962550     NaN  20558.0    42.0      2.0    1.0  20160615      NaN   NaN   \n",
       "...         ...      ...     ...      ...    ...       ...      ...   ...   \n",
       "3095512      TX  20602.0    40.0      2.0    1.0  20160430      CDJ   NaN   \n",
       "2872019      WA  20594.0    30.0      1.0    1.0  20160430      KMP   NaN   \n",
       "2872018      WA      NaN    30.0      1.0    1.0  20160430      KMP   NaN   \n",
       "2902934     NaN  20582.0    66.0      2.0    1.0  20160430      BGT   NaN   \n",
       "2902931     NaN      NaN    66.0      2.0    1.0  20160430      BGT   NaN   \n",
       "\n",
       "        entdepa entdepd entdepu matflag  biryear   dtaddto gender insnum  \\\n",
       "2966361       P     NaN     NaN     NaN   1985.0  05072016      M   3890   \n",
       "2960934       A       L     NaN       M   1981.0  05212016      F   3980   \n",
       "2960935       A       L     NaN       M   2006.0  05212016      F   3969   \n",
       "2961618       A       L     NaN       M   1983.0  05232016      F   3987   \n",
       "2962550       A       L     NaN       M   1974.0  05242016      U   3980   \n",
       "...         ...     ...     ...     ...      ...       ...    ...    ...   \n",
       "3095512       Z       I     NaN       M   1976.0  10282016      M    NaN   \n",
       "2872019       U       O     NaN       M   1986.0  05302016      M    NaN   \n",
       "2872018       G     NaN     NaN     NaN   1986.0  05302016      M    NaN   \n",
       "2902934       U       I     NaN       M   1950.0  10292016      M    NaN   \n",
       "2902931       G     NaN     NaN     NaN   1950.0  10292016      M    NaN   \n",
       "\n",
       "        airline        admnum  fltno visatype  \n",
       "2966361      7C  0.000000e+00  03404       CP  \n",
       "2960934      OZ  0.000000e+00  00607      GMT  \n",
       "2960935      OZ  0.000000e+00  00607      GMT  \n",
       "2961618      7C  0.000000e+00  03402      GMT  \n",
       "2962550      OZ  0.000000e+00    NaN      GMT  \n",
       "...         ...           ...    ...      ...  \n",
       "3095512     NaN  9.492138e+10   LAND       B2  \n",
       "2872019      EK  9.495698e+10    227       B1  \n",
       "2872018      EK  9.495698e+10  00227       B1  \n",
       "2902934     VES  9.499540e+10  AMSTR       B2  \n",
       "2902931     VES  9.499540e+10  AMSTR       B2  \n",
       "\n",
       "[40108 rows x 28 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if addnum is unique and can be used as primary key\n",
    "mask = df.admnum.duplicated(keep=False)\n",
    "df[mask].sort_values(by=['admnum'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Airport data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 55075 entries, 0 to 55074\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   ident         55075 non-null  object \n",
      " 1   type          55075 non-null  object \n",
      " 2   name          55075 non-null  object \n",
      " 3   elevation_ft  48069 non-null  float64\n",
      " 4   continent     27356 non-null  object \n",
      " 5   iso_country   54828 non-null  object \n",
      " 6   iso_region    55075 non-null  object \n",
      " 7   municipality  49399 non-null  object \n",
      " 8   gps_code      41030 non-null  object \n",
      " 9   iata_code     9189 non-null   object \n",
      " 10  local_code    28686 non-null  object \n",
      " 11  coordinates   55075 non-null  object \n",
      "dtypes: float64(1), object(11)\n",
      "memory usage: 5.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "airport_data = pd.read_csv(r'./data/airport/airport-codes_csv.csv', sep=',', encoding='UTF-8')\n",
    "print(airport_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if ident can be primary key\n",
    "len(airport_data)- len(airport_data.ident.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>237.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>Newport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-91.254898, 35.6087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                                name  elevation_ft  \\\n",
       "0   00A       heliport                   Total Rf Heliport          11.0   \n",
       "1  00AA  small_airport                Aero B Ranch Airport        3435.0   \n",
       "2  00AK  small_airport                        Lowell Field         450.0   \n",
       "3  00AL  small_airport                        Epps Airpark         820.0   \n",
       "4  00AR         closed  Newport Hospital & Clinic Heliport         237.0   \n",
       "\n",
       "  continent iso_country iso_region  municipality gps_code iata_code  \\\n",
       "0       NaN          US      US-PA      Bensalem      00A       NaN   \n",
       "1       NaN          US      US-KS         Leoti     00AA       NaN   \n",
       "2       NaN          US      US-AK  Anchor Point     00AK       NaN   \n",
       "3       NaN          US      US-AL       Harvest     00AL       NaN   \n",
       "4       NaN          US      US-AR       Newport      NaN       NaN   \n",
       "\n",
       "  local_code                            coordinates  \n",
       "0        00A     -74.93360137939453, 40.07080078125  \n",
       "1       00AA                 -101.473911, 38.704022  \n",
       "2       00AK            -151.695999146, 59.94919968  \n",
       "3       00AL  -86.77030181884766, 34.86479949951172  \n",
       "4        NaN                    -91.254898, 35.6087  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ident               0\n",
       "type                0\n",
       "name                0\n",
       "elevation_ft     7006\n",
       "continent       27719\n",
       "iso_country       247\n",
       "iso_region          0\n",
       "municipality     5676\n",
       "gps_code        14045\n",
       "iata_code       45886\n",
       "local_code      26389\n",
       "coordinates         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for null values\n",
    "airport_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coordinates are not in numeric format. Need to convert to numeric and clean null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test clean up. Final clean up will be done using sql\n",
    "values = {'elevation_ft': -99999, 'continent':'-','iso_country':'-', 'iso_country':'-', 'municipality':'-', 'gps_code':'-', 'iata_code':'-', 'local_code':'-'}\n",
    "airport_data.fillna(value=values, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### us-cities-demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "us_cities = pd.read_csv(r'./data/us-city-demo/us-cities-demographics.csv', sep=';', encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2891 entries, 0 to 2890\n",
      "Data columns (total 12 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   City                    2891 non-null   object \n",
      " 1   State                   2891 non-null   object \n",
      " 2   Median Age              2891 non-null   float64\n",
      " 3   Male Population         2888 non-null   float64\n",
      " 4   Female Population       2888 non-null   float64\n",
      " 5   Total Population        2891 non-null   int64  \n",
      " 6   Number of Veterans      2878 non-null   float64\n",
      " 7   Foreign-born            2878 non-null   float64\n",
      " 8   Average Household Size  2875 non-null   float64\n",
      " 9   State Code              2891 non-null   object \n",
      " 10  Race                    2891 non-null   object \n",
      " 11  Count                   2891 non-null   int64  \n",
      "dtypes: float64(6), int64(2), object(4)\n",
      "memory usage: 271.2+ KB\n"
     ]
    }
   ],
   "source": [
    "us_cities.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City                       0\n",
       "State                      0\n",
       "Median Age                 0\n",
       "Male Population            3\n",
       "Female Population          3\n",
       "Total Population           0\n",
       "Number of Veterans        13\n",
       "Foreign-born              13\n",
       "Average Household Size    16\n",
       "State Code                 0\n",
       "Race                       0\n",
       "Count                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_cities.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040.0</td>\n",
       "      <td>46799.0</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819.0</td>\n",
       "      <td>8229.0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127.0</td>\n",
       "      <td>87105.0</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821.0</td>\n",
       "      <td>33878.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040.0</td>\n",
       "      <td>143873.0</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829.0</td>\n",
       "      <td>86253.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State  Median Age  Male Population  \\\n",
       "0     Silver Spring       Maryland        33.8          40601.0   \n",
       "1            Quincy  Massachusetts        41.0          44129.0   \n",
       "2            Hoover        Alabama        38.5          38040.0   \n",
       "3  Rancho Cucamonga     California        34.5          88127.0   \n",
       "4            Newark     New Jersey        34.6         138040.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "2            46799.0             84839              4819.0        8229.0   \n",
       "3            87105.0            175232              5821.0       33878.0   \n",
       "4           143873.0            281913              5829.0       86253.0   \n",
       "\n",
       "   Average Household Size State Code                       Race  Count  \n",
       "0                    2.60         MD         Hispanic or Latino  25924  \n",
       "1                    2.39         MA                      White  58723  \n",
       "2                    2.58         AL                      Asian   4759  \n",
       "3                    3.18         CA  Black or African-American  24437  \n",
       "4                    2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_cities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Clean column names\n",
    "us_cities.columns = ['city', 'state_name', 'median_age', 'male_population', 'female_population',\n",
    "       'total_population', 'num_veterans', 'foreign_born',\n",
    "       'average_household_size', 'state_code', 'race', 'count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_cities['city'] = us_cities['city'].str.upper()\n",
    "us_cities['state_name'] = us_cities['city'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "567"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(us_cities.city.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>port_code</th>\n",
       "      <th>addr</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALC</td>\n",
       "      <td>ALCAN, AK</td>\n",
       "      <td>ALCAN</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANC</td>\n",
       "      <td>ANCHORAGE, AK</td>\n",
       "      <td>ANCHORAGE</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BAR</td>\n",
       "      <td>BAKER AAF - BAKER ISLAND, AK</td>\n",
       "      <td>BAKER AAF - BAKER ISLAND</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DAC</td>\n",
       "      <td>DALTONS CACHE, AK</td>\n",
       "      <td>DALTONS CACHE</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PIZ</td>\n",
       "      <td>DEW STATION PT LAY DEW, AK</td>\n",
       "      <td>DEW STATION PT LAY DEW</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  port_code                          addr                      city state\n",
       "0       ALC                     ALCAN, AK                     ALCAN    AK\n",
       "1       ANC                 ANCHORAGE, AK                 ANCHORAGE    AK\n",
       "2       BAR  BAKER AAF - BAKER ISLAND, AK  BAKER AAF - BAKER ISLAND    AK\n",
       "3       DAC             DALTONS CACHE, AK             DALTONS CACHE    AK\n",
       "4       PIZ    DEW STATION PT LAY DEW, AK    DEW STATION PT LAY DEW    AK"
      ]
     },
     "execution_count": 846,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_ports.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Load temperature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "fname = './data/world-temp/GlobalLandTemperaturesByCity.csv'\n",
    "temperature_data = pd.read_csv(fname, index_col=0, parse_dates=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1743-11-01</th>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743-12-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1744-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1744-02-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1744-03-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            AverageTemperature  AverageTemperatureUncertainty   City  Country  \\\n",
       "dt                                                                              \n",
       "1743-11-01               6.068                          1.737  Ã…rhus  Denmark   \n",
       "1743-12-01                 NaN                            NaN  Ã…rhus  Denmark   \n",
       "1744-01-01                 NaN                            NaN  Ã…rhus  Denmark   \n",
       "1744-02-01                 NaN                            NaN  Ã…rhus  Denmark   \n",
       "1744-03-01                 NaN                            NaN  Ã…rhus  Denmark   \n",
       "\n",
       "           Latitude Longitude  \n",
       "dt                             \n",
       "1743-11-01   57.05N    10.33E  \n",
       "1743-12-01   57.05N    10.33E  \n",
       "1744-01-01   57.05N    10.33E  \n",
       "1744-02-01   57.05N    10.33E  \n",
       "1744-03-01   57.05N    10.33E  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 8599212 entries, 1743-11-01 to 2013-09-01\n",
      "Data columns (total 6 columns):\n",
      " #   Column                         Dtype  \n",
      "---  ------                         -----  \n",
      " 0   AverageTemperature             float64\n",
      " 1   AverageTemperatureUncertainty  float64\n",
      " 2   City                           object \n",
      " 3   Country                        object \n",
      " 4   Latitude                       object \n",
      " 5   Longitude                      object \n",
      "dtypes: float64(2), object(4)\n",
      "memory usage: 459.2+ MB\n"
     ]
    }
   ],
   "source": [
    "temperature_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AverageTemperature               364130\n",
       "AverageTemperatureUncertainty    364130\n",
       "City                                  0\n",
       "Country                               0\n",
       "Latitude                              0\n",
       "Longitude                             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# null will be replaced with -999, longitude, latitude in NSEW format. will be coverted to numeric to be compatible with airport data\n",
    "temperature_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Clean up\n",
    "# short_temp_data.columns = ['avg_temp', 'avg_temp_error', 'city', 'country', 'latitude', 'longitude']\n",
    "# short_temp_data['city']  = short_temp_data.city.str.upper()\n",
    "# short_temp_data['country']  = short_temp_data.country.str.upper()\n",
    "# us_temp_data = short_temp_data[short_temp_data['country']=='UNITED STATES'].copy()\n",
    "# us_temp_data['latitude'] = us_temp_data['latitude'].apply(lambda x: (1 if x[-1] == 'N' else -1) * float(x[:-1]))\n",
    "# us_temp_data['longitude'] = us_temp_data['longitude'].apply(lambda x: (1 if x[-1]=='E' else -1)*float(x[:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read SAS data dictionary, parse to extract dimension tables.\n",
    "with open(r'./data/immigration/I94_SAS_Labels_Descriptions.SAS') as file:\n",
    "    file_string = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sas_source_code_tables_data = [\n",
    "  {'table_name': 'country',\n",
    "   'parse_string': 'i94cntyl',\n",
    "   'end_string': ';',\n",
    "   'columns': ['country_code', 'country'],\n",
    "   'dq_checks': [{'check_sql': \"SELECT COUNT(*) FROM country WHERE country_code is null\", 'expected_result': 0}]\n",
    "  },\n",
    "  {'table_name': 'entry_port',\n",
    "   'parse_string': 'i94prtl',\n",
    "   'end_string': ';',\n",
    "   'columns': ['port_code', 'addr', 'city', 'state'],\n",
    "   'dq_checks': [{'check_sql': \"SELECT COUNT(*) FROM entry_port WHERE port_code is null\", 'expected_result': 0}]\n",
    "  },\n",
    "  {'table_name': 'arrival_mode',\n",
    "   'parse_string': 'i94model',\n",
    "   'end_string': ';',\n",
    "   'columns': ['arrival_code', 'arrival_type'],\n",
    "   'dq_checks': [{'check_sql': \"SELECT COUNT(*) FROM arrival_mode WHERE arrival_code is null\", 'expected_result': 0}]\n",
    "  },\n",
    "  {'table_name': 'region',\n",
    "   'parse_string': 'i94addrl',\n",
    "   'end_string': ';',\n",
    "   'columns': ['region_code', 'region_name'],\n",
    "   'dq_checks': [{'check_sql': \"SELECT COUNT(*) FROM region_code WHERE region_code is null\", 'expected_result': 0}]\n",
    "  },\n",
    "  {'table_name': 'visa_type',\n",
    "   'parse_string': 'I94VISA',\n",
    "   'end_string': '*/',\n",
    "   'columns': ['visa_code', 'visa_type'],\n",
    "   'dq_checks': [{'check_sql': \"SELECT COUNT(*) FROM visa_type WHERE visa_code is null\", 'expected_result': 0}]\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_sas_file(file_string, parse_string, end_string, table_name, columns):\n",
    "    '''Function accepts sas file as a string, segments data tables base on parse_string and end_string.\n",
    "        It will further process string segment to clean and extract code and value fields as lists.\n",
    "        Function returns the ziped list of code and value.\n",
    "    \n",
    "    '''\n",
    "    filtered_string = file_string[file_string.index(parse_string):]\n",
    "    filtered_string = filtered_string[:filtered_string.index(end_string)]\n",
    "    # clean string  by removing ' and tabs\n",
    "    filtered_string = filtered_string.replace(\"'\", \"\").replace('\\t', \"\")\n",
    "    # Remove line with parse_string\n",
    "    filtered_list = filtered_string.split('\\n')\n",
    "    filtered_list = filtered_list[1:] \n",
    "\n",
    "    df = pd.DataFrame(filtered_list)\n",
    "    \n",
    "    df[[0,1]] = df[0].str.split('=', n = 1, expand = True)\n",
    "    df[0] = df[0].str.strip()\n",
    "    df[1] = df[1].str.strip()\n",
    "    df[0] = df[0].str.upper()\n",
    "    df[1] = df[1].str.upper()\n",
    "    df = df.dropna()\n",
    "   \n",
    "    if table_name=='entry_port':\n",
    "       \n",
    "        df[2] = df[1].apply(lambda x: x.split(',')[0].upper())\n",
    "        df[3] = df[1].apply(lambda x: x.split(',')[-1].upper())\n",
    "        df[2] = df[2].str.strip()\n",
    "        df[3] = df[3].str.strip()#ARPT\n",
    "        df[2] = df[2].str.replace(' #ARPT', \"\", regex = False)\n",
    "        df[3] = df[3].str.replace(' (BPS)', \"\", regex = False)\n",
    "        df[3] = df[3].str.replace(' #ARPT', \"\", regex = False)\n",
    "    \n",
    "        df.columns=columns\n",
    "    \n",
    "    else:\n",
    " \n",
    "        df.columns=columns\n",
    "\n",
    "    return df.drop_duplicates().dropna()\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test \n",
    "us_ports = parse_sas_file(file_string, 'i94prtl', ';', 'entry_port', ['port_code', 'addr', 'city', 'state']) \n",
    "#us_ports = parse_sas_file(file_string, 'I94VISA', '*/', 'visa_type', ['code', 'value'])\n",
    "#us_ports = parse_sas_file(file_string, 'i94model', ';', 'arrival_mode', ['code', 'value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>port_code</th>\n",
       "      <th>addr</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALC</td>\n",
       "      <td>ALCAN, AK</td>\n",
       "      <td>ALCAN</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANC</td>\n",
       "      <td>ANCHORAGE, AK</td>\n",
       "      <td>ANCHORAGE</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BAR</td>\n",
       "      <td>BAKER AAF - BAKER ISLAND, AK</td>\n",
       "      <td>BAKER AAF - BAKER ISLAND</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DAC</td>\n",
       "      <td>DALTONS CACHE, AK</td>\n",
       "      <td>DALTONS CACHE</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PIZ</td>\n",
       "      <td>DEW STATION PT LAY DEW, AK</td>\n",
       "      <td>DEW STATION PT LAY DEW</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  port_code                          addr                      city state\n",
       "0       ALC                     ALCAN, AK                     ALCAN    AK\n",
       "1       ANC                 ANCHORAGE, AK                 ANCHORAGE    AK\n",
       "2       BAR  BAKER AAF - BAKER ISLAND, AK  BAKER AAF - BAKER ISLAND    AK\n",
       "3       DAC             DALTONS CACHE, AK             DALTONS CACHE    AK\n",
       "4       PIZ    DEW STATION PT LAY DEW, AK    DEW STATION PT LAY DEW    AK"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_ports[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country\n",
      "entry_port\n",
      "arrival_mode\n",
      "region\n",
      "visa_type\n"
     ]
    }
   ],
   "source": [
    "# file strig is defind above\n",
    "for item in sas_source_code_tables_data:\n",
    "    parse_string = item.get('parse_string')\n",
    "    end_string = item.get('end_string')\n",
    "    table_name = item.get('table_name')\n",
    "    columns = item.get('columns')\n",
    "\n",
    "  \n",
    "    print(table_name)\n",
    " \n",
    "\n",
    "\n",
    "    dm_df = parse_sas_file(file_string, parse_string, end_string, table_name , columns)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read temperature data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Datasets have multiple quality issues such as null values, mixed numeric and string data, date formatting issues etc. Data cleanup is performed in Airflow using table specific sql queries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "U.S. Immigration analytical database has a star schema with one fact table and multiple dimension tables. Dimension tables are directly populated through truncate, copy pattern or special operator that parses and loads the data. Dimension tables are relatively small in size. Consequently, truncate-copy pattern is a reasonable way to to maintain idempotent data pipeline without compromising the performance. Dimension tables are distributed across all nodes for faster query performance. Immigration dataset is first loaded into staging a staging table, which will then be cleaned and populates that fact table.\n",
    "\n",
    "Additional datasets containing world temperature, US city demographics, and airport codes can be combined with main database to answer various analytical questions. These datasets are loaded into staging tables, cleaned and transformed into more analytical friendly formats.\n",
    "\n",
    "Database schema is shown below:\n",
    "\n",
    "![Main-dataset](./images/er_capstone.png)\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "Following custom operators were developed for loading datasets from s3 bucket to RedShift, cleaning, and validation. \n",
    "\n",
    "- SASfileToRedshiftOperator : Parse and load tables from SAS data dictionary to Redshift.\n",
    "- S3ToRedshiftOperator : Load files in CSV or Parquet format to Redshift using copy command.\n",
    "- LoadFactOperator : Clean and load immigration fact table from staging table.\n",
    "- CleanTablesOperator : Perform various data cleanup operations, for example fill null values, convert from string to numeric format etc.\n",
    "- DataQualityOperator : Performs data quality checks to ensure tables are populated without errors using pre-defined set of queries and expected result.\n",
    "\n",
    "Airflow data pipeline is shown below:\n",
    "\n",
    "![pipeline](./images/graph_success.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Implemented using Airflow. See README.md for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Table specific quality checks are defined in Airflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "   1.  Apache Airflow is a great open source tool for easy scheduling of etl workflows. In this project Airflow is used to keep the analytical database up to date and to ensure data quality.\n",
    "\n",
    "   1. Redshift offers Massively parallel processing (MPP) that enables fast execution of the most complex queries operating on large amounts of data. Columnar storage of tables reduces i/o requirements and improves analytical query performance. Redshift is easily scalable and can be configured within minutes.\n",
    "\n",
    "   1. S3 object storage was selected as the raw data storage solution due to performance and redshift compatibility advantages.\n",
    "\n",
    "* Propose how often the data should be updated and why.\n",
    "    1. Immigration raw datasets are updated on monthly basis. Consequently, pipeline is scheduled monthly. It can be adjusted if data is available more frequently.\n",
    "\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    "    1. Airflow and Redshift are easily scalable to handle increased data load.\n",
    "\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    "    1. In this case DAG need to be scheduled on daily basis to ensure most updated datasets are available for the dash board update. \n",
    "\n",
    " * The database needed to be accessed by 100+ people.\n",
    "    1. AWS offers many options for identity and access management based on their roles. Redshift cluster resources may need scaling up based on demand. Redshift offer auto scaling based on demand, which maximizes performance while optimizing cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
